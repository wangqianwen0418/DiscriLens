{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8504254366323332"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_range_cols(data):\n",
    "    range_col = [] # columns that fit numerical values into ranges\n",
    "    for col in data.select_dtypes(exclude=['int64', 'float', 'float64']).columns:\n",
    "        if any(item in data[col][0] for item in ['>', '<']): \n",
    "            range_col.append(col)\n",
    "                \n",
    "    return range_col\n",
    "def findRange(thresholds, v):\n",
    "    for i, th in enumerate(thresholds):\n",
    "        if(v <= th):\n",
    "            if i==0:\n",
    "                    return \"x<{}\".format(th)\n",
    "            elif i == len(thresholds)-1:\n",
    "                    return \"x>{}\".format(thresholds[i-1])\n",
    "            else:\n",
    "                    return \"{}<x<{}\".format(thresholds[i-1], thresholds[i])\n",
    "                \n",
    "def convert_cate(arr):\n",
    "    n = 4 #parts to be divided\n",
    "    maxValue = max(arr)\n",
    "    minValue = min(arr)\n",
    "    thresholds = [ math.floor(i*(maxValue-minValue)/n)+minValue for i in range(n+1)]\n",
    "\n",
    "    #print([findRange(thresholds, i) for i in arr])\n",
    "    \n",
    "    return pd.Series([findRange(thresholds, i) for i in arr])\n",
    "\n",
    "\n",
    "def num2cate(dataIn):\n",
    "    df = dataIn[:]\n",
    "#     new_data = pd.DataFrame()\n",
    "    for k in df.columns:\n",
    "        if(k in df.select_dtypes(include=['int64','float64'])):\n",
    "            values = pd.to_numeric(df[k])\n",
    "            df[k] = convert_cate(values.tolist())\n",
    "        \n",
    "    return df\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "class DataEncoder(object):\n",
    "    def __init__(self, class_column='class', cat_columns=None):\n",
    "        self.class_column = class_column\n",
    "        self.cat_columns = cat_columns\n",
    "\n",
    "        # these will be trained with fit_encoders()\n",
    "        self.column_encoders = {} # label encoder\n",
    "        self.cat_encoder = None # one-hot encoder\n",
    "        self.label_encoder = None # label encoder\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit one-hot encoders for categorical features and an integer encoder for\n",
    "        the label. These can be used later to transform raw data into a form\n",
    "        that ATM can work with.\n",
    "\n",
    "        data: pd.DataFrame of unprocessed data\n",
    "        \"\"\"\n",
    "        if self.class_column not in data.columns:\n",
    "            raise KeyError('Class column \"%s\" not found in dataset!' %\n",
    "                           self.class_column)\n",
    "            \n",
    "        range_col = find_range_cols(data)\n",
    "                \n",
    "        self.range_col = range_col\n",
    "            \n",
    "\n",
    "        # encode categorical columns, leave ordinal values alone\n",
    "        if self.cat_columns is None:\n",
    "            cats = data.drop([self.class_column]+range_col, axis=1).select_dtypes(exclude=['int64'])\n",
    "            self.cat_columns = cats.columns\n",
    "        else:\n",
    "            cats = data[self.cat_columns].drop(range_col, axis=1).select_dtypes(exclude=['int64'])\n",
    "            \n",
    "        self.cat_cols = cats.columns\n",
    "        \n",
    "        for cat_name in cats.columns:   \n",
    "        # save the indices of categorical columns for one-hot encoding\n",
    "\n",
    "            # encode each feature as an integer in range(unique_vals)\n",
    "            le = LabelEncoder()\n",
    "            cats[cat_name] = le.fit_transform(cats[cat_name])\n",
    "            self.column_encoders[cat_name] = le\n",
    "\n",
    "        # One-hot encode the whole feature matrix.\n",
    "        # Set sparse to False so that we can test for NaNs in the output\n",
    "        self.cat_encoder = OneHotEncoder(n_values='auto',sparse=False)\n",
    "        # if Category column exists          \n",
    "        if cats.shape[1] != 0:\n",
    "            self.cat_encoder.fit(cats)\n",
    "\n",
    "        # Train an encoder for the label as well\n",
    "        labels = np.array(data[[self.class_column]])\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(labels)\n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Convert a DataFrame of labeled data to a feature matrix in the form\n",
    "        that ATM can use.\n",
    "        \"\"\"\n",
    "        y = self.transform_y(data)\n",
    "        X = self.transform_x(data)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def transform_x(self, data, onehot=False):\n",
    "        \"\"\"\n",
    "        only transform x, for the generated data\n",
    "        \"\"\"\n",
    "        cats = data[self.cat_columns]\n",
    "\n",
    "        # encode each categorical feature as an integer\n",
    "        for column, encoder in list(self.column_encoders.items()):\n",
    "            cats[column] = encoder.transform(cats[column])\n",
    "\n",
    "        # one-hot encode the categorical features\n",
    "        if cats.shape[1] != 0 and onehot:\n",
    "            X = self.cat_encoder.transform(cats)\n",
    "        else:\n",
    "            X = cats\n",
    "        \n",
    "        if self.class_column in data:\n",
    "            nums = data.drop([self.class_column], axis=1).select_dtypes(include=['int64']).values\n",
    "        else:\n",
    "            nums = data.select_dtypes(include=['int64']).values\n",
    "            \n",
    "       \n",
    "        # transform range cols into integrate. e.g., <4 -> 1; 4<x<7 -> 2\n",
    "        ranges = []\n",
    "        for col in self.range_col:\n",
    "            values = data[col]\n",
    "            ranges.append( self.range2int(values) )\n",
    "#         print(X.shape, nums.shape, ranges.shape)\n",
    "        if(ranges==[]):\n",
    "            X = np.concatenate((X, nums), axis=1)\n",
    "        else:\n",
    "            ranges = np.transpose( np.array(ranges) )\n",
    "            X = np.concatenate((X, nums, ranges), axis=1)\n",
    "        return X\n",
    "    \n",
    "    def transform_y(self, data):\n",
    "        if self.class_column in data:\n",
    "            # pull labels into a separate series and transform them to integers\n",
    "            labels = np.array(data[[self.class_column]])\n",
    "            y = self.label_encoder.transform(labels)\n",
    "            # drop the label column and transform the remaining features\n",
    "        else:\n",
    "            y = None\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def range2int(self, values):\n",
    "        ranges = []\n",
    "        for v in values:\n",
    "            if v not in ranges:\n",
    "                ranges.append(v)\n",
    "        \n",
    "        def sort_key(x):\n",
    "            num_strings = re.findall('\\d+', x)\n",
    "            # 'undefined' is in the front\n",
    "            if len(num_strings)==0:\n",
    "                return -1\n",
    "            # x> 1, x<7\n",
    "            elif len(num_strings)==1:\n",
    "                return int(num_strings[0])*2\n",
    "            # 1<x<7\n",
    "            else:\n",
    "                nums = map(int, num_strings) # string to number\n",
    "                return sum(nums)\n",
    "                \n",
    "        ranges.sort(key=sort_key)\n",
    "        return list(map(lambda x: ranges.index(x), values))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\" Process data into a form that ATM can use. \"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "def fit_model(model, data):\n",
    "        '''\n",
    "        Args:\n",
    "            data(panda DataFrame): training dataset\n",
    "\n",
    "        Return:\n",
    "            model: an already trained sklearn model\n",
    "            score(list<number>): cross validate score\n",
    "        '''\n",
    "        \n",
    "        encoder = DataEncoder()\n",
    "        encoder.fit(data)\n",
    "        x, y = encoder.transform(data)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "        \n",
    "        \n",
    "#         plot_learning_curve(model,'',x_train, y_train,ylim=(0.7, 1.01), cv=5, n_jobs=4)\n",
    "        \n",
    "#         score = plot_time_curve(model,x_train, x_test, y_train, y_test,3)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        score = accuracy_score(y_test, model.predict(x_test))\n",
    "        # score = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=4) \n",
    "        return model, encoder, score\n",
    "\n",
    "    \n",
    "\n",
    "def plot_time_curve(model, x_train, x_test, y_train, y_test,epochNum):\n",
    "    \n",
    "    plotDataTrain = []\n",
    "    plotDataTest = []\n",
    "    for i in range(epochNum):\n",
    "        model.fit(x_train,y_train)\n",
    "        plotDataTrain.append(model.score(x_train,y_train))\n",
    "        plotDataTest.append(model.score(x_test,y_test))\n",
    "        print('epoch: ',i)\n",
    "        \n",
    "    x_axis = np.linspace(0,epochNum,epochNum)\n",
    "    print(x_axis,plotDataTrain)\n",
    "    plt.plot(x_axis,plotDataTrain,c='red')\n",
    "    plt.plot(x_axis,plotDataTest,c='blue')\n",
    "    plt.show()\n",
    "    \n",
    "    return plotDataTest[len(plotDataTest)-1]\n",
    "    \n",
    "    \n",
    "xgb = XGBClassifier(\n",
    "                max_depth=10, \n",
    "                learning_rate=0.1, \n",
    "                n_estimators=100,seed=10,\n",
    "            )\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "                algorithm = \"ball_tree\",\n",
    "                leaf_size = 40,\n",
    "                metric = \"manhattan\",\n",
    "                n_neighbors = 10\n",
    "            )\n",
    "lr = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "                penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "                verbose=0, warm_start=False\n",
    "            )\n",
    "\n",
    "df = pd.read_csv('adult.csv')\n",
    "df2 = pd.read_csv('bank.csv')\n",
    "\n",
    "# df2 = df2.replace(' ?').dropna(axis=0)\n",
    "\n",
    "# for i,var in df2.iterrows():\n",
    "#     df2.at[i,'class'] = '1' if df2.at[i,'class']==' >50K' else '0'\n",
    "\n",
    "# df3 = num2cate(df2)\n",
    "# df2.to_csv('adult_new2.csv',index=False)\n",
    "\n",
    "_,_,score = fit_model(xgb,df2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
