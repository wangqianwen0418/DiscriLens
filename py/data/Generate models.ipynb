{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "\n",
    "import random\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"bank_term_deposit\"\n",
    "filename = \"bank_term_deposit_clean.csv\"\n",
    "\n",
    "sample_number = 3000\n",
    "protected_attribute = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range_cols(data):\n",
    "    range_col = [] # columns that fit numerical values into ranges\n",
    "    for col in data.select_dtypes(exclude=['int', 'float64']).columns:\n",
    "        if any(item in data[col][0] for item in ['>', '<']): \n",
    "            range_col.append(col)\n",
    "                \n",
    "    return range_col\n",
    "\n",
    "class DataEncoder(object):\n",
    "    def __init__(self, class_column='class', cat_columns=None):\n",
    "        self.class_column = class_column\n",
    "        self.cat_columns = cat_columns\n",
    "\n",
    "        # these will be trained with fit_encoders()\n",
    "        self.column_encoders = {} # label encoder\n",
    "        self.cat_encoder = None # one-hot encoder\n",
    "        self.label_encoder = None # label encoder\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit one-hot encoders for categorical features and an integer encoder for\n",
    "        the label. These can be used later to transform raw data into a form\n",
    "        that ATM can work with.\n",
    "\n",
    "        data: pd.DataFrame of unprocessed data\n",
    "        \"\"\"\n",
    "        if self.class_column not in data.columns:\n",
    "            raise KeyError('Class column \"%s\" not found in dataset!' %\n",
    "                           self.class_column)\n",
    "            \n",
    "        range_col = find_range_cols(data)\n",
    "                \n",
    "        self.range_col = range_col\n",
    "        print(range_col)\n",
    "            \n",
    "\n",
    "        # encode categorical columns, leave ordinal values alone\n",
    "        if self.cat_columns is None:\n",
    "            cats = data.drop([self.class_column]+range_col, axis=1).select_dtypes(exclude=['int'])\n",
    "            self.cat_columns = cats.columns\n",
    "        else:\n",
    "            cats = data[self.cat_columns].drop(range_col, axis=1).select_dtypes(exclude=['int'])\n",
    "            \n",
    "        self.cat_cols = cats.columns\n",
    "#         print(cats.columns)\n",
    "        \n",
    "        for cat_name in cats.columns:   \n",
    "        # save the indices of categorical columns for one-hot encoding\n",
    "\n",
    "            # encode each feature as an integer in range(unique_vals)\n",
    "            le = LabelEncoder()\n",
    "            cats[cat_name] = le.fit_transform(cats[cat_name])\n",
    "            self.column_encoders[cat_name] = le\n",
    "\n",
    "        # One-hot encode the whole feature matrix.\n",
    "        # Set sparse to False so that we can test for NaNs in the output\n",
    "        self.cat_encoder = OneHotEncoder(sparse=False)\n",
    "        # if Category column exists          \n",
    "        if cats.shape[1] != 0:\n",
    "            self.cat_encoder.fit(cats)\n",
    "\n",
    "        # Train an encoder for the label as well\n",
    "        labels = np.array(data[[self.class_column]])\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(labels)\n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Convert a DataFrame of labeled data to a feature matrix in the form\n",
    "        that ATM can use.\n",
    "        \"\"\"\n",
    "        y = self.transform_y(data)\n",
    "        X = self.transform_x(data)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def transform_x(self, data):\n",
    "        \"\"\"\n",
    "        only transform x, for the generated data\n",
    "        \"\"\"\n",
    "        cats = data[self.cat_columns]\n",
    "\n",
    "        # encode each categorical feature as an integer\n",
    "        for column, encoder in list(self.column_encoders.items()):\n",
    "            cats[column] = encoder.transform(cats[column])\n",
    "\n",
    "        # one-hot encode the categorical features\n",
    "        if cats.shape[1] != 0:\n",
    "            X = self.cat_encoder.transform(cats)\n",
    "        else:\n",
    "            X = cats\n",
    "        \n",
    "#         print(X)\n",
    "        if self.class_column in data:\n",
    "            nums = data.drop([self.class_column], axis=1).select_dtypes(include=['int']).values\n",
    "        else:\n",
    "            nums = data.select_dtypes(include=['int']).values\n",
    "            \n",
    "       \n",
    "        # transform range cols into integrate. e.g., <4 -> 1; 4<x<7 -> 2\n",
    "        ranges = []\n",
    "        for col in self.range_col:\n",
    "            values = data[col]\n",
    "            ranges.append( self.range2int(values) )\n",
    "        ranges = np.transpose( np.array(ranges) )\n",
    "#         print(X.shape, nums.shape, ranges.shape)\n",
    "        \n",
    "        X = np.concatenate((X, nums, ranges), axis=1)\n",
    "        return X\n",
    "    \n",
    "    def transform_y(self, data):\n",
    "        if self.class_column in data:\n",
    "            # pull labels into a separate series and transform them to integers\n",
    "            labels = np.array(data[[self.class_column]])\n",
    "            y = self.label_encoder.transform(labels)\n",
    "            # drop the label column and transform the remaining features\n",
    "        else:\n",
    "            y = None\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def range2int(self, values):\n",
    "        ranges = []\n",
    "        for v in values:\n",
    "            if v not in ranges:\n",
    "                ranges.append(v)\n",
    "        \n",
    "        def sort_key(x):\n",
    "            num_strings = re.findall('\\d+', x)\n",
    "            # 'undefined' is in the front\n",
    "            if len(num_strings)==0:\n",
    "                return -1\n",
    "            # x> 1, x<7\n",
    "            elif len(num_strings)==1:\n",
    "                return int(num_strings[0])*2\n",
    "            # 1<x<7\n",
    "            else:\n",
    "                nums = map(int, num_strings) # string to number\n",
    "                return sum(nums)\n",
    "                \n",
    "        ranges.sort(key=sort_key)\n",
    "        return list(map(lambda x: ranges.index(x), values))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\" Process data into a form that ATM can use. \"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'euribor3m']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jyz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jyz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(foldername + '/' + filename)\n",
    "\n",
    "# drop rows with any NA values\n",
    "data = data.dropna(how='any')\n",
    "data = data[0:1000]\n",
    "\n",
    "encoder = DataEncoder()\n",
    "encoder.fit(data)\n",
    "x_train, y_train = encoder.transform(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cls = SVC(\n",
    "    C = 0.0484055070919,\n",
    "    cache_size = 15000,\n",
    "    class_weight = \"balanced\",\n",
    "    gamma = 424.665365448,\n",
    "    kernel = \"rbf\",\n",
    "    max_iter = 50000,\n",
    "    probability = True,\n",
    "    shrinking = True)\n",
    "\n",
    "\n",
    "mlp_cls = MLPClassifier(\n",
    "    activation = \"relu\",\n",
    "    alpha = 0.00146693288878,\n",
    "    batch_size = \"auto\",\n",
    "    hidden_layer_sizes= (189,50, ),\n",
    "    learning_rate = \"constant\",\n",
    "    learning_rate_init = 0.898892816545,\n",
    "    solver = \"sgd\"\n",
    ")\n",
    "\n",
    "rf_cls = RandomForestClassifier(\n",
    "    bootstrap=True, \n",
    "    class_weight=None, \n",
    "    criterion='entropy', \n",
    "    max_depth=10, \n",
    "    max_features=0.45, \n",
    "    max_leaf_nodes=None, \n",
    "    min_impurity_decrease=1e-07, \n",
    "    min_samples_leaf=6, \n",
    "    min_samples_split=7, \n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    n_estimators=512, \n",
    "    n_jobs=1, \n",
    "    oob_score=False, \n",
    "    random_state=3, \n",
    "    verbose=0, \n",
    "    warm_start=False\n",
    ")\n",
    "\n",
    "knn_cls = KNeighborsClassifier(\n",
    "    algorithm = \"ball_tree\",\n",
    "    leaf_size = 40,\n",
    "    metric = \"manhattan\",\n",
    "    n_neighbors = 17\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn [ 0.96039604  0.96039604  0.96039604  0.96039604  0.97        0.97\n",
      "  0.96969697  0.96969697  0.96969697  0.96969697] rf [ 0.96039604  0.96039604  0.96039604  0.96039604  0.97        0.97\n",
      "  0.96969697  0.96969697  0.96969697  0.96969697]\n"
     ]
    }
   ],
   "source": [
    "# svm_score = cross_val_score(svm_cls, x_train, y_train, scoring='accuracy', cv=10) \n",
    "# mlp_score = cross_val_score(mlp_cls, x_train, y_train, scoring='accuracy', cv=10) \n",
    "\n",
    "knn_cls.fit(x_train, y_train)\n",
    "knn_score = cross_val_score(knn_cls, x_train, y_train, scoring='accuracy', cv=10) \n",
    "\n",
    "rf_cls.fit(x_train, y_train)\n",
    "rf_score = cross_val_score(rf_cls, x_train, y_train, scoring='accuracy', cv=10) \n",
    "\n",
    "print('knn', knn_score, 'rf', rf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "class DataGene(object):\n",
    "    \n",
    "    def __init__(self, data, sample_num=10, class_col='class'):\n",
    "        self.data = data\n",
    "        self.sample_num = sample_num\n",
    "        self.class_col = 'class'\n",
    "        \n",
    "    def get_samples(self):\n",
    "        features = self.data.drop([self.class_col], axis=1)\n",
    "#         print(features)\n",
    "        range_cols = find_range_cols(self.data)\n",
    "        print(range_cols)\n",
    "        cat_cols = features.select_dtypes(exclude=['int']).drop(range_cols, axis=1).columns\n",
    "        num_cols = features.select_dtypes(include=['int']).columns\n",
    "        print(cat_cols)\n",
    "        print(num_cols)\n",
    "        samples = []\n",
    "        \n",
    "        for i in range(self.sample_num):\n",
    "            sample_cat = [\n",
    "                random.choice(encoder.column_encoders[cat_name].classes_)\n",
    "                for cat_name in cat_cols\n",
    "            ]\n",
    "            sample_num = [\n",
    "                random.choice( list(set(features[num_name])) )\n",
    "                for num_name in num_cols\n",
    "            ]\n",
    "            sample_range = [\n",
    "                random.choice( list(set(features[range_name])) )\n",
    "                for range_name in range_cols\n",
    "            ]\n",
    "            sample = sample_cat + sample_num + sample_range\n",
    "            samples.append(sample)\n",
    "            \n",
    "        \n",
    "        samples = pd.DataFrame(samples, columns=list(cat_cols)+list(num_cols)+range_cols)\n",
    "        return samples        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'euribor3m']\n",
      "Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
      "       'month', 'day_of_week', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
      "       'cons.conf.idx', 'nr.employed'],\n",
      "      dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyz/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# generate new samples\n",
    "dataGene = DataGene(data, sample_num=sample_number)\n",
    "new_samples = dataGene.get_samples()\n",
    "# encode sample data\n",
    "x_samples, y_samples = encoder.transform(new_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate samples to describe model behavior\n",
    "def add_col(df, new_col, col_name):\n",
    "    new_df = df.copy()\n",
    "    new_df[col_name] = pd.Series(np.asarray(new_col), index= df.index) \n",
    "    return new_df\n",
    "\n",
    "y_samples_knn = knn_cls.predict(x_samples)\n",
    "y_samples_rf = rf_cls.predict(x_samples)\n",
    "\n",
    "\n",
    "# pandas data frame\n",
    "knn_samples = add_col(new_samples, y_samples_knn, 'class') \n",
    "rf_samples = add_col(new_samples, y_samples_rf, 'class')\n",
    "\n",
    "model_samples = knn_samples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find key attributes\n",
    "import re\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "from pycausal import search as s\n",
    "\n",
    "pc = pc()\n",
    "pc.start_vm()\n",
    "\n",
    "\n",
    "\n",
    "def findKeyAttrs(samples, protect_attr, result_attr = 'class'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        samples(pandas data frames): \n",
    "        protect_attr(string || Array<string>): \n",
    "    Return:\n",
    "        key_attrs(list<string>): a list of key attributes that directly influence the decision\n",
    "    \"\"\"\n",
    "    key_attrs = []\n",
    "    ### use bayes Est to find the key attributes\n",
    "    ### slow, extract more key attributes \n",
    "#     graph = s.bayesEst(samples, depth = 0, alpha = 0.05, verbose = True)\n",
    "    ### OR use Fast Greedy Equivalence Search\n",
    "    ### faster than bayes, get less key attributes\n",
    "    graph = s.tetradrunner()\n",
    "    graph.getAlgorithmParameters(algoId = 'fges', scoreId = 'bdeu')\n",
    "\n",
    "    graph.run(algoId = 'fges', dfs = data, scoreId = 'bdeu', priorKnowledge = None, dataType = 'discrete',\n",
    "           structurePrior = 0.5, samplePrior = 0.5, maxDegree = 5, faithfulnessAssumed = True, verbose = False)\n",
    "    \n",
    "#     graph.getNodes()\n",
    "    \n",
    "    for edge in graph.getEdges():\n",
    "        if 'class' in edge:\n",
    "            # extract attr name from the edge\n",
    "            # remove --> or --o or --- and white space\n",
    "            attr = re.sub(r'-+>?o?|{}|\\s+'.format(result_attr), '', edge)\n",
    "            key_attrs.append(attr)\n",
    "            \n",
    "            \n",
    "    # remove protect attrs        \n",
    "    if type(protect_attr) is not str: \n",
    "        # if protect attr is a list\n",
    "        for a in protect_attr:\n",
    "            if a in key_attrs:\n",
    "                key_attrs.remove(a)\n",
    "    elif protect_attr in key_attrs:\n",
    "        # if protect attr is a string\n",
    "        key_attrs.remove(protect_attr)\n",
    "    return key_attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samplePrior: Sample prior (min = 1.0) (java.lang.Double) [default:1.0]\n",
      "structurePrior: Structure prior coefficient (min = 1.0) (java.lang.Double) [default:1.0]\n",
      "faithfulnessAssumed: Yes if (one edge) faithfulness should be assumed (java.lang.Boolean) [default:true]\n",
      "symmetricFirstStep: Yes if the first step step for FGES should do scoring for both X->Y and Y->X (java.lang.Boolean) [default:false]\n",
      "maxDegree: The maximum degree of the graph (min = -1) (java.lang.Integer) [default:100]\n",
      "verbose: Yes if verbose output should be printed or logged (java.lang.Boolean) [default:true]\n",
      "numberResampling: The number of resampling iterations (min = 0) (java.lang.Integer) [default:0]\n",
      "resampleSize: The resample size (min = 1) (java.lang.Integer) [default:1]\n",
      "resamplingWithReplacement: Yes, if resampling with replacement (bootstrapping) (java.lang.Boolean) [default:true]\n",
      "resamplingEnsemble: Ensemble method: Preserved (0), Highest (1), Majority (2) (java.lang.Integer) [default:1]\n",
      "\n",
      "\n",
      "protected attribute: age ['57<x<77', '17<x<37', '37<x<57'] \n",
      "\n",
      "key attributes: ['day_of_week', 'duration'] \n",
      "\n",
      "{'day_of_week': ['wed', 'thu', 'mon', 'tue', 'fri'], 'duration': ['1229<x<2459', '0<x<1229', 'x>3688']} \n",
      "\n",
      "candidate attribute: ['housing'] {'housing': ['no', 'yes']} \n",
      "\n",
      "{'day_of_week': 'wed', 'duration': '1229<x<2459', 'housing': 'no'} 88\n",
      "57<x<77 0.00 1.00 26\n",
      "17<x<37 0.00 1.00 38\n",
      "37<x<57 0.00 1.00 24\n",
      "{'day_of_week': 'wed', 'duration': '1229<x<2459', 'housing': 'yes'} 94\n",
      "57<x<77 0.00 1.00 33\n",
      "17<x<37 0.00 1.00 32\n",
      "37<x<57 0.00 1.00 29\n",
      "{'day_of_week': 'wed', 'duration': '0<x<1229', 'housing': 'no'} 98\n",
      "57<x<77 0.00 1.00 36\n",
      "17<x<37 0.00 1.00 33\n",
      "37<x<57 0.00 1.00 29\n",
      "{'day_of_week': 'wed', 'duration': '0<x<1229', 'housing': 'yes'} 107\n",
      "57<x<77 0.00 1.00 36\n",
      "17<x<37 0.00 1.00 40\n",
      "37<x<57 0.00 1.00 31\n",
      "{'day_of_week': 'wed', 'duration': 'x>3688', 'housing': 'no'} 112\n",
      "57<x<77 0.00 1.00 39\n",
      "17<x<37 0.00 1.00 42\n",
      "37<x<57 0.00 1.00 31\n",
      "{'day_of_week': 'wed', 'duration': 'x>3688', 'housing': 'yes'} 94\n",
      "57<x<77 0.00 1.00 27\n",
      "17<x<37 0.00 1.00 39\n",
      "37<x<57 0.00 1.00 28\n",
      "{'day_of_week': 'thu', 'duration': '1229<x<2459', 'housing': 'no'} 102\n",
      "57<x<77 0.00 1.00 33\n",
      "17<x<37 0.00 1.00 35\n",
      "37<x<57 0.00 1.00 34\n",
      "{'day_of_week': 'thu', 'duration': '1229<x<2459', 'housing': 'yes'} 98\n",
      "57<x<77 0.00 1.00 23\n",
      "17<x<37 0.00 1.00 39\n",
      "37<x<57 0.00 1.00 36\n",
      "{'day_of_week': 'thu', 'duration': '0<x<1229', 'housing': 'no'} 102\n",
      "57<x<77 0.00 1.00 36\n",
      "17<x<37 0.00 1.00 30\n",
      "37<x<57 0.00 1.00 36\n",
      "{'day_of_week': 'thu', 'duration': '0<x<1229', 'housing': 'yes'} 106\n",
      "57<x<77 0.00 1.00 30\n",
      "17<x<37 0.00 1.00 37\n",
      "37<x<57 0.00 1.00 39\n",
      "{'day_of_week': 'thu', 'duration': 'x>3688', 'housing': 'no'} 99\n",
      "57<x<77 0.00 1.00 42\n",
      "17<x<37 0.00 1.00 26\n",
      "37<x<57 0.00 1.00 31\n",
      "{'day_of_week': 'thu', 'duration': 'x>3688', 'housing': 'yes'} 117\n",
      "57<x<77 0.00 1.00 28\n",
      "17<x<37 0.00 1.00 38\n",
      "37<x<57 0.00 1.00 51\n",
      "{'day_of_week': 'mon', 'duration': '1229<x<2459', 'housing': 'no'} 98\n",
      "57<x<77 0.00 1.00 36\n",
      "17<x<37 0.00 1.00 26\n",
      "37<x<57 0.00 1.00 36\n",
      "{'day_of_week': 'mon', 'duration': '1229<x<2459', 'housing': 'yes'} 96\n",
      "57<x<77 0.00 1.00 36\n",
      "17<x<37 0.00 1.00 25\n",
      "37<x<57 0.00 1.00 35\n",
      "{'day_of_week': 'mon', 'duration': '0<x<1229', 'housing': 'no'} 102\n",
      "57<x<77 0.00 1.00 34\n",
      "17<x<37 0.00 1.00 40\n",
      "37<x<57 0.00 1.00 28\n",
      "{'day_of_week': 'mon', 'duration': '0<x<1229', 'housing': 'yes'} 100\n",
      "57<x<77 0.00 1.00 34\n",
      "17<x<37 0.00 1.00 35\n",
      "37<x<57 0.00 1.00 31\n",
      "{'day_of_week': 'mon', 'duration': 'x>3688', 'housing': 'no'} 97\n",
      "57<x<77 0.00 1.00 31\n",
      "17<x<37 0.00 1.00 37\n",
      "37<x<57 0.00 1.00 29\n",
      "{'day_of_week': 'mon', 'duration': 'x>3688', 'housing': 'yes'} 111\n",
      "57<x<77 0.00 1.00 44\n",
      "17<x<37 0.00 1.00 30\n",
      "37<x<57 0.00 1.00 37\n",
      "{'day_of_week': 'tue', 'duration': '1229<x<2459', 'housing': 'no'} 97\n",
      "57<x<77 0.00 1.00 26\n",
      "17<x<37 0.00 1.00 33\n",
      "37<x<57 0.00 1.00 38\n",
      "{'day_of_week': 'tue', 'duration': '1229<x<2459', 'housing': 'yes'} 115\n",
      "57<x<77 0.00 1.00 42\n",
      "17<x<37 0.00 1.00 32\n",
      "37<x<57 0.00 1.00 41\n",
      "{'day_of_week': 'tue', 'duration': '0<x<1229', 'housing': 'no'} 110\n",
      "57<x<77 0.00 1.00 37\n",
      "17<x<37 0.00 1.00 43\n",
      "37<x<57 0.00 1.00 30\n",
      "{'day_of_week': 'tue', 'duration': '0<x<1229', 'housing': 'yes'} 80\n",
      "57<x<77 0.00 1.00 25\n",
      "17<x<37 0.00 1.00 23\n",
      "37<x<57 0.00 1.00 32\n",
      "{'day_of_week': 'tue', 'duration': 'x>3688', 'housing': 'no'} 91\n",
      "57<x<77 0.00 1.00 31\n",
      "17<x<37 0.00 1.00 34\n",
      "37<x<57 0.00 1.00 26\n",
      "{'day_of_week': 'tue', 'duration': 'x>3688', 'housing': 'yes'} 82\n",
      "57<x<77 0.00 1.00 22\n",
      "17<x<37 0.00 1.00 35\n",
      "37<x<57 0.00 1.00 25\n",
      "{'day_of_week': 'fri', 'duration': '1229<x<2459', 'housing': 'no'} 105\n",
      "57<x<77 0.00 1.00 41\n",
      "17<x<37 0.00 1.00 39\n",
      "37<x<57 0.00 1.00 25\n",
      "{'day_of_week': 'fri', 'duration': '1229<x<2459', 'housing': 'yes'} 111\n",
      "57<x<77 0.00 1.00 35\n",
      "17<x<37 0.00 1.00 37\n",
      "37<x<57 0.00 1.00 39\n",
      "{'day_of_week': 'fri', 'duration': '0<x<1229', 'housing': 'no'} 89\n",
      "57<x<77 0.00 1.00 33\n",
      "17<x<37 0.00 1.00 28\n",
      "37<x<57 0.00 1.00 28\n",
      "{'day_of_week': 'fri', 'duration': '0<x<1229', 'housing': 'yes'} 97\n",
      "57<x<77 0.00 1.00 32\n",
      "17<x<37 0.00 1.00 30\n",
      "37<x<57 0.00 1.00 35\n",
      "{'day_of_week': 'fri', 'duration': 'x>3688', 'housing': 'no'} 96\n",
      "57<x<77 0.00 1.00 35\n",
      "17<x<37 0.00 1.00 34\n",
      "37<x<57 0.00 1.00 27\n",
      "{'day_of_week': 'fri', 'duration': 'x>3688', 'housing': 'yes'} 106\n",
      "57<x<77 0.00 1.00 28\n",
      "17<x<37 0.00 1.00 37\n",
      "37<x<57 0.00 1.00 41\n"
     ]
    }
   ],
   "source": [
    "# candidate attribute\n",
    "candi_attrs = ['housing']\n",
    "candi_vals = {}\n",
    "for candi_attr in candi_attrs:\n",
    "    candi_vals[candi_attr] = list(set(model_samples[candi_attr]))\n",
    "\n",
    "# identify candidate groups\n",
    "protect_attr = protected_attribute\n",
    "protect_vals = list(set(model_samples[protect_attr]))\n",
    "\n",
    "key_attrs = findKeyAttrs(model_samples, protect_attr)\n",
    "key_vals = {}\n",
    "for key_attr in key_attrs:\n",
    "    key_vals[key_attr] = list(set(model_samples[key_attr]))\n",
    "    \n",
    "all_groups = []\n",
    "\n",
    "all_attrs = key_attrs + candi_attrs\n",
    "all_vals = {}\n",
    "for all_attr in all_attrs:\n",
    "    all_vals[all_attr] = list(set(model_samples[all_attr]))\n",
    "\n",
    "print('\\n')\n",
    "print('protected attribute:', protect_attr, protect_vals, '\\n')\n",
    "print('key attributes:', key_attrs, '\\n')\n",
    "print(key_vals, '\\n')\n",
    "print('candidate attribute:', candi_attrs, candi_vals, '\\n')\n",
    "\n",
    "\n",
    "def generate_groups(all_vals, depth, index, all_groups):\n",
    "    '''\n",
    "    Args: \n",
    "        key_vals(dict): e.g., {'atrribute_a':['a', 'b', 'c'], 'attribute_b': ['m', 'n', 'k']}\n",
    "        depth(int): recursive depth\n",
    "        index(dict): the choosen value of each key attribute. e.g.,  {'atrribute_a':'a', 'attribute_b': 'k'}\n",
    "        all_groups: a list of index\n",
    "    \n",
    "    '''\n",
    "#     print('a', key_vals, key_attrs, depth)\n",
    "    for k in all_vals[ all_attrs[depth] ]:\n",
    "        index_ = copy.deepcopy(index)\n",
    "        index_[all_attrs[depth]] = k\n",
    "        if depth < len(all_attrs)-1: \n",
    "            depth_ = depth+1 \n",
    "            generate_groups(all_vals, depth_, index_, all_groups)\n",
    "        else:\n",
    "            all_groups.append(index_)\n",
    "    \n",
    "\n",
    "generate_groups(all_vals, 0, {}, all_groups)\n",
    "# print(key_groups)\n",
    "\n",
    "for group in all_groups:\n",
    "    group_items = model_samples.copy()\n",
    "    for attr in group:\n",
    "        group_items = group_items.loc[group_items[attr]==group[attr]]\n",
    "    print(group, len(group_items))\n",
    "    if len(group_items)>0:\n",
    "        for val in protect_vals:\n",
    "            # based on protected attribute\n",
    "            group_items_ = group_items.loc[group_items[protect_attr] == val]\n",
    "            if len(group_items)>0:\n",
    "#                 group_reject = group_items_.loc[group_items_['class'] == 0]\n",
    "#                 group_accept = group_items_.loc[group_items_['class'] == 1]\n",
    "#                 p_0 = len(group_reject)/len(group_items_)\n",
    "#                 p_1 = len(group_accept)/len(group_items_)\n",
    "#                 print(val, \"{:.2f}\".format(p_0), \"{:.2f}\".format(p_1), len(group_items_))\n",
    "                group_high= group_items_.loc[group_items_['class'] == 0]\n",
    "                group_low = group_items_.loc[group_items_['class'] == 1]\n",
    "#                 group_middle = group_items_.loc[group_items_['class'] == 2]\n",
    "                p_1 = len(group_low)/len(group_items_)\n",
    "#                 p_2 = len(group_middle)/len(group_items_)\n",
    "                p_0 = len(group_high)/len(group_items_)\n",
    "#                 print(val, \"{:.2f}\".format(p_1), \"{:.2f}\".format(p_2), \"{:.2f}\".format(p_0), len(group_items_))\n",
    "                print(val, \"{:.2f}\".format(p_1), \"{:.2f}\".format(p_0), len(group_items_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
